{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "from imutils.video import  WebcamVideoStream\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ear(eye):    # eye aspect ratio\n",
    "    vertical1_dist = dist.euclidean(eye[1], eye[5])\n",
    "    vertical2_dist = dist.euclidean(eye[2], eye[4])\n",
    "    horizontal_dist = dist.euclidean(eye[0], eye[3])\n",
    "    aspect_ratio = (vertical1_dist + vertical2_dist) / (2.0 * horizontal_dist)\n",
    "    return aspect_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.30\n",
    "framenos = 44\n",
    "age_list = ['(0,2)', '(4,6)', '(8,12)', '(15,18)', '(21,32)', '(38,43)', '(48,53)', '(60,100)']\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_caffe_models():\n",
    "    age_net = cv2.dnn.readNetFromCaffe('deploy_age.prototxt', 'age_net.caffemodel')\n",
    "    return age_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "predictor = dlib.shape_predictor(predictor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'res10_300x300_ssd_iter_140000.caffemodel')\n",
    "def detector(frame):\n",
    "    dlibrect=False\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300),(104.0, 177.0, 123.0))\n",
    "    face_net.setInput(blob)\n",
    "    detections = face_net.forward()\n",
    "    for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence < 0.5:\n",
    "                continue\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int32\")\n",
    "            dlibrect = dlib.rectangle(int(startX), int(startY), int(endX), int(endY))\n",
    "    return dlibrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lx,ly) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rx,ry) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =  WebcamVideoStream(src=0).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 640\n"
     ]
    }
   ],
   "source": [
    "first_frame = file.read()\n",
    "(iheight,iwidth) = first_frame.shape[:2]\n",
    "print(iheight,iwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_to_bb(det):\n",
    "    x = det.left()\n",
    "    y = det.top()\n",
    "    w = det.right() \n",
    "    h = det.bottom() \n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_detector(age_net):\n",
    "    counter = 0\n",
    "    while True:\n",
    "        frame = file.read()\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        det = detector(frame)\n",
    "        if(det):\n",
    "            ishape = predictor(gray,det)\n",
    "            ishape = face_utils.shape_to_np(ishape)\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(det)\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)                \n",
    "            key = cv2.waitKey(1)\n",
    "            #for (x,y) in ishape:\n",
    "                #cv2.circle(frame,(x,y),1,(0,255,0),1)\n",
    "            \n",
    "            face_img = frame[y:y + h, h:h + w].copy()\n",
    "            blob=cv2.dnn.blobFromImage(face_img,1,(227,227),MODEL_MEAN_VALUES,swapRB=False)\n",
    "            age_net.setInput(blob)\n",
    "            age_preds = age_net.forward()\n",
    "            age = age_list[age_preds[0].argmax()]\n",
    "            overlay_text = \"%s\" % (age)\n",
    "            cv2.putText(frame, overlay_text,(x,y+h), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "              \n",
    "            leftEye = ishape[lx:ly]\n",
    "            rightEye = ishape[rx:ry]\n",
    "\n",
    "            leftEar = ear(leftEye)\n",
    "            rightEar = ear(rightEye)\n",
    "            avgEar = (leftEar+rightEar)/2\n",
    "            if avgEar < threshold:\n",
    "                counter += 1\n",
    "                if counter >= framenos:\n",
    "                    cv2.putText(frame, \"DROWSY\",(x,y),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "                    cv2.putText(frame, \"NOT ELIGIBLE FOR DRIVING-Drowsy\",(20,20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "                          \n",
    "            else:\n",
    "                counter = 0\n",
    "                cv2.putText(frame, \"NOT DR0WSY\",(x,y),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                if overlay_text in (age_list[0],age_list[1],age_list[2],age_list[3]):\n",
    "                    cv2.putText(frame, \"NOT ELIGIBLE FOR DRIVING-Underage and Drowsy\",(20,20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "                else:\n",
    "                    cv2.putText(frame, \"ELIGIBLE FOR DRIVING\",(20,20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"NO FACE PRESENT\",(20,20),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        cv2.imshow('original frame',frame)\n",
    "        frame = cv2.resize(frame,(iwidth,iheight))\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            file.stop()\n",
    "            break\n",
    "    file.stream.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    age_net = load_caffe_models()\n",
    "    video_detector(age_net)  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
